{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiny NeRF with Flax\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/myagues/flax_nerf/blob/main/tiny_nerf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "This is a simplied version of the method presented in *NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis*, using Flax and supporting multiple device TPU or GPU training.\n",
    "\n",
    "Original work:\n",
    "- [Project Website](https://www.matthewtancik.com/nerf)\n",
    "- [arXiv Paper](https://arxiv.org/abs/2003.08934)\n",
    "- [Full Code](https://www.github.com/bmild/nerf)\n",
    "\n",
    "Components not included in the notebook:\n",
    "- 5D input including view directions\n",
    "- Hierarchical Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://www.github.com/google/flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "import time\n",
    "\n",
    "import imageio\n",
    "import jax\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from flax import jax_utils, linen as nn, optim\n",
    "from flax.training import common_utils\n",
    "from jax import numpy as jnp, lax, random\n",
    "from jax.config import config\n",
    "from typing import Any, Callable, Sequence\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline\n",
    "\n",
    "config.enable_omnistaging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boilerplate for connecting JAX to TPU\n",
    "if \"google.colab\" in str(get_ipython()) and \"COLAB_TPU_ADDR\" in os.environ:\n",
    "    import requests\n",
    "\n",
    "    url = f\"http://{os.environ['COLAB_TPU_ADDR'].split(':')[0]}:8475/requestversion/tpu_driver0.1-dev20200416\"\n",
    "    resp = requests.post(url)\n",
    "    assert resp.status_code == 200\n",
    "    TPU_DRIVER_MODE = 1\n",
    "\n",
    "    config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
    "    config.FLAGS.jax_backend_target = f\"grpc://{os.environ['COLAB_TPU_ADDR']}\"\n",
    "    print(f\"Registered TPU: {config.FLAGS.jax_backend_target}\")\n",
    "else:\n",
    "    print(\"No TPU detected.\")\n",
    "print(jax.local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"tiny_nerf_data.npz\"):\n",
    "    !curl -O https://people.eecs.berkeley.edu/~bmild/nerf/tiny_nerf_data.npz\n",
    "\n",
    "data = np.load(\"tiny_nerf_data.npz\")\n",
    "images = jnp.array(data[\"images\"])\n",
    "poses = data[\"poses\"]\n",
    "focal = float(data[\"focal\"])\n",
    "_, img_h, img_w, _ = images.shape\n",
    "\n",
    "testimg, testpose = images[101], poses[101]\n",
    "images = images[:100, ..., :3]\n",
    "poses = poses[:100]\n",
    "\n",
    "print(f\"Images shape: {images.shape}\")\n",
    "print(f\"Poses shape: {poses.shape}\")\n",
    "print(f\"Focal value: {focal:.5f}\")\n",
    "\n",
    "plt.imshow(testimg)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize NeRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.partial(jax.jit, static_argnums=(0, 1, 2))\n",
    "def get_rays(img_h, img_w, focal, c2w):\n",
    "    \"\"\"Generate ray matrices.\"\"\"\n",
    "    i, j = jnp.meshgrid(jnp.arange(img_w), jnp.arange(img_h), indexing=\"xy\")\n",
    "    dirs = jnp.stack(\n",
    "        [(i - img_w * 0.5) / focal, -(j - img_h * 0.5) / focal, -jnp.ones_like(i)], -1\n",
    "    )\n",
    "    rays_d = jnp.einsum(\"ijl,kl\", dirs, c2w[:3, :3])\n",
    "    rays_o = jnp.broadcast_to(c2w[:3, -1], rays_d.shape)\n",
    "    return jnp.stack([rays_o, rays_d])\n",
    "\n",
    "\n",
    "def render_rays(\n",
    "    net_fn,\n",
    "    rays,\n",
    "    near=2.0,\n",
    "    far=6.0,\n",
    "    num_samples=64,\n",
    "    batch_size=10000,\n",
    "    rng=None,\n",
    "    rand=False,\n",
    "):\n",
    "    rays_o, rays_d = rays\n",
    "    # Compute 3D query points\n",
    "    z_vals = jnp.linspace(near, far, num_samples)\n",
    "    z_shape = [*rays_o.shape[:-1], num_samples]\n",
    "    if rand:\n",
    "        z_vals += random.uniform(rng, z_shape) * (far - near) / num_samples\n",
    "    pts = rays_o[..., None, :] + rays_d[..., None, :] * z_vals[..., :, None]\n",
    "\n",
    "    # Run network\n",
    "    raw = lax.map(net_fn, jnp.reshape(pts, [-1, batch_size, 3]))\n",
    "    raw = jnp.reshape(raw, [*pts.shape[:-1], 4])\n",
    "    \n",
    "    # Compute opacities and colors\n",
    "    sigma_a = nn.relu(raw[..., 3])\n",
    "    rgb = nn.sigmoid(raw[..., :3])\n",
    "\n",
    "    # Do volume rendering\n",
    "    dists = z_vals[..., 1:] - z_vals[..., :-1]\n",
    "    dists = jnp.concatenate(\n",
    "        [dists, jnp.broadcast_to([1e10], dists[..., :1].shape)], axis=-1\n",
    "    )\n",
    "\n",
    "    alpha = 1.0 - jnp.exp(-sigma_a * dists)\n",
    "    alpha_ = jnp.clip(1.0 - alpha, 1e-10, 1.0)\n",
    "    trans = jnp.concatenate([jnp.ones_like(alpha_[..., :1]), alpha_[..., :-1]], -1)\n",
    "    weights = alpha * jnp.cumprod(trans, -1)  # (img_h, img_w, num_samples)\n",
    "\n",
    "    rgb_map = jnp.einsum(\"...k,...kl\", weights, rgb)\n",
    "    depth_map = jnp.einsum(\"...k,...k\", weights, z_vals)\n",
    "    acc_map = jnp.einsum(\"...k->...\", weights)\n",
    "\n",
    "    return rgb_map, depth_map, acc_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of memory (OOM) errors can appear when using TPUs (TPUv2 in Colab have 8GB of HBM memory, whereas GPUs range from 12GB to 16GB), as they use a padding mechanism (read the [TPU performance guide](https://cloud.google.com/tpu/docs/performance-guide#consequences_of_tiling) for more information). To work around these limitations, you can:\n",
    "- reduce `net_width` and / or `nwt_depth` (worse results)\n",
    "- enable `nn.remat` decorator (slower time per step). More about `jax.remat` in [JAX #1749](https://github.com/google/jax/pull/1749)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeRF(nn.Module):\n",
    "    net_depth: int = 8\n",
    "    net_width: int = 256\n",
    "    skips: Sequence[int] = (4,)\n",
    "    periodic_fns: Sequence[Callable] = (jnp.sin, jnp.cos)\n",
    "    output_channels: int = 4\n",
    "    use_embedding: bool = True\n",
    "    l_embed: int = 6\n",
    "    dtype: Any = jnp.float32\n",
    "\n",
    "    def embed(self, inputs):\n",
    "        batch_size, _ = inputs.shape\n",
    "        inputs_freq = jax.vmap(lambda x: inputs * 2.0 ** x)(jnp.arange(self.l_embed))\n",
    "        fns = jnp.stack([fn(inputs_freq) for fn in self.periodic_fns])\n",
    "        fns = fns.swapaxes(0, 2).reshape([batch_size, -1])\n",
    "        fns = jnp.concatenate([inputs, fns], axis=-1)\n",
    "        return fns\n",
    "\n",
    "    @nn.remat\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs_pts):\n",
    "        x = self.embed(inputs_pts) if self.use_embedding else inputs_pts\n",
    "        for i in range(self.net_depth):\n",
    "            x = nn.Dense(self.net_width, dtype=self.dtype)(x)\n",
    "            x = nn.relu(x)\n",
    "            if i in self.skips:\n",
    "                x = jnp.concatenate([x, inputs_pts], axis=-1)\n",
    "        x = nn.Dense(self.output_channels, dtype=self.dtype)(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def initialized(key, input_pts_shape):\n",
    "    model = NeRF()\n",
    "    initial_params = model.init(\n",
    "        {\"params\": key},\n",
    "        jnp.ones(input_pts_shape),\n",
    "    )\n",
    "    return model, initial_params[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(opt, rng):\n",
    "    \"\"\"Train step.\"\"\"\n",
    "    rng0, rng1 = random.split(rng)\n",
    "    idx = random.randint(rng0, (1,), minval=0, maxval=images.shape[0])[0]\n",
    "\n",
    "    def loss_fn(params):\n",
    "        model_fn = lambda x: model.apply({\"params\": params}, x)\n",
    "        rgb, *_ = render_rays(model_fn, train_rays[idx], rng=rng1, rand=True)\n",
    "        return jnp.mean(jnp.square(rgb - images[idx]))\n",
    "\n",
    "    grads = jax.grad(loss_fn)(opt.target)\n",
    "    grads = lax.pmean(grads, axis_name=\"batch\")\n",
    "    new_opt = opt.apply_gradient(grads)\n",
    "    return new_opt\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def evaluate(params):\n",
    "    \"\"\"Evaluation step w/ PSNR metric.\"\"\"\n",
    "    model_fn = lambda x: model.apply({\"params\": params}, x)\n",
    "    rgb, *_ = render_rays(model_fn, test_rays)\n",
    "    loss = jnp.mean(jnp.square(rgb - testimg))\n",
    "    psnr = -10.0 * jnp.log(loss) / jnp.log(10.0)\n",
    "    return rgb, psnr\n",
    "\n",
    "\n",
    "p_update = jax.pmap(functools.partial(update), axis_name=\"batch\")\n",
    "\n",
    "train_rays = lax.map(lambda pose: get_rays(img_h, img_w, focal, pose), poses)\n",
    "test_rays = get_rays(img_h, img_w, focal, testpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(0)\n",
    "key, rng = random.split(key)\n",
    "model, params = initialized(key, (10000, 3))\n",
    "optimizer = optim.Adam(learning_rate=5e-4).create(params)\n",
    "optimizer = jax_utils.replicate(optimizer)\n",
    "\n",
    "psnrs = []\n",
    "iternums = []\n",
    "num_iters = 1000\n",
    "i_plot = 50\n",
    "\n",
    "for i in range(num_iters + 1):\n",
    "    t = time.time()\n",
    "    rng, rng_step = random.split(rng)\n",
    "    sharded_rngs = common_utils.shard_prng_key(rng_step)\n",
    "    optimizer = p_update(optimizer, sharded_rngs)\n",
    "\n",
    "    if i % i_plot == 0:\n",
    "        t_end = time.time() - t\n",
    "        optimizer_ = jax_utils.unreplicate(optimizer)\n",
    "        rgb, psnr = evaluate(optimizer_.target)\n",
    "        print(f\"Iters: {i:4d}\\t{t_end:2.5f} sec/iter\\tPSNR: {psnr:.5f}\")\n",
    "        psnrs.append(psnr)\n",
    "        iternums.append(i)\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "        ax1.imshow(rgb)\n",
    "        ax1.axis(\"off\")\n",
    "        ax2.plot(iternums, psnrs)\n",
    "        plt.show()\n",
    "\n",
    "optimizer = jax_utils.unreplicate(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_t = lambda t: jnp.array(\n",
    "    [\n",
    "        [1, 0, 0, 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [0, 0, 1, t],\n",
    "        [0, 0, 0, 1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "rot_phi = lambda phi: jnp.array(\n",
    "    [\n",
    "        [1, 0, 0, 0],\n",
    "        [0, jnp.cos(phi), -jnp.sin(phi), 0],\n",
    "        [0, jnp.sin(phi), jnp.cos(phi), 0],\n",
    "        [0, 0, 0, 1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "rot_theta = lambda th: jnp.array(\n",
    "    [\n",
    "        [jnp.cos(th), 0, -jnp.sin(th), 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [jnp.sin(th), 0, jnp.cos(th), 0],\n",
    "        [0, 0, 0, 1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def get_rgb(c2w):\n",
    "    rays = get_rays(img_h, img_w, focal, c2w[:3, :4])\n",
    "    model_fn = lambda x: model.apply({\"params\": optimizer.target}, x)\n",
    "    rgb, depth, acc = render_rays(model_fn, rays)\n",
    "    img = (255 * jnp.clip(rgb, 0, 1)).astype(jnp.uint8)\n",
    "    return rgb, depth, acc, img\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def pose_spherical(theta, phi, radius):\n",
    "    c2w = trans_t(radius)\n",
    "    c2w = rot_phi(phi / 180.0 * jnp.pi) @ c2w\n",
    "    c2w = rot_theta(theta / 180.0 * jnp.pi) @ c2w\n",
    "    c2w = jnp.array([[-1, 0, 0, 0], [0, 0, 1, 0], [0, 1, 0, 0], [0, 0, 0, 1]]) @ c2w\n",
    "    return c2w\n",
    "\n",
    "\n",
    "def f(**kwargs) -> None:\n",
    "    c2w = pose_spherical(**kwargs)\n",
    "    rgb, _, _, _ = get_rgb(c2w)\n",
    "    img = jnp.clip(rgb, 0, 1)\n",
    "\n",
    "    plt.figure(2, figsize=(20, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "sldr = lambda v, mi, ma: widgets.FloatSlider(value=v, min=mi, max=ma, step=0.01)\n",
    "\n",
    "names = [\n",
    "    [\"theta\", [100.0, 0.0, 360]],\n",
    "    [\"phi\", [-30.0, -90, 0]],\n",
    "    [\"radius\", [4.0, 3.0, 5.0]],\n",
    "]\n",
    "\n",
    "interactive_plot = widgets.interactive(f, **{s[0]: sldr(*s[1]) for s in names})\n",
    "output = interactive_plot.children[-1]\n",
    "output.layout.height = \"475px\"\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render 360 Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_angle = jnp.linspace(0.0, 360.0, 120, endpoint=False)\n",
    "v_c2w = jax.vmap(lambda th: pose_spherical(th, -30.0, 4.0))(video_angle)\n",
    "*_, frames = zip(*map(get_rgb, v_c2w))\n",
    "frames = map(np.array, frames)\n",
    "\n",
    "file_name = \"video.mp4\"\n",
    "imageio.mimwrite(file_name, tuple(frames), fps=30, quality=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%HTML\n",
    "# <video width=\"500\" controls autoplay loop>\n",
    "#   <source src=\"video.mp4\" type=\"video/mp4\">\n",
    "# </video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "mp4 = open(\"video.mp4\", \"rb\").read()\n",
    "data_url = f\"data:video/mp4;base64,{b64encode(mp4).decode()}\"\n",
    "HTML(\n",
    "    \"\"\"\n",
    "<video width=500 controls autoplay loop>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\"\n",
    "    % data_url\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
